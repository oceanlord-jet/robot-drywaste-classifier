# Robotics Project: Automated Garbage Classification

**Automated Garbage Classification Robot**

This repository implements an end-to-end system for automatically classifying and sorting dry waste using a Niryo One robotic arm, deep learning-based vision models, and both real-world and simulated environments.

---

## Repository Structure

```plaintext
.
â”œâ”€â”€ Model/                                  # Image classification pipeline
â”‚   â”œâ”€â”€ README.md                           # Model training, evaluation, and interpretability
â”‚   â””â”€â”€ garbage-classification.ipynb        # Jupyter notebook with data exploration and training
â”œâ”€â”€ Robot/                                  # Niryo One integration and hardware control
â”‚   â”œâ”€â”€ README.md                           # Setup and usage instructions for physical hardware
â”‚   â”œâ”€â”€ classify_function.py                # Image classification helper using EfficientNetB0
â”‚   â”œâ”€â”€ watchy.py                           # Main sorting workflow controlling the robot
â”‚   â””â”€â”€ captured_image.jpg                  # Example snapshot from the robot camera
â”œâ”€â”€ Simulation/                             # Virtual testing environment
â”‚   â””â”€â”€ README.md                           # Simulation setup and logic for sorting pipeline
â””â”€â”€ README.md                               # Overview of full robotics project (this file)
```

---

## Module Descriptions

### 1. Model

Contains the deep learning pipeline and dataset organization for waste classification:

```plaintext
Model/
â”œâ”€â”€ README.md                   # Detailed instructions for training and evaluation
â”œâ”€â”€ garbage-classification.ipynb# Jupyter notebook with data exploration and model training
â”œâ”€â”€ global-classification/      # Raw image dataset organized by category
â”‚   â”œâ”€â”€ metal/                  # Metal waste images
â”‚   â”œâ”€â”€ plastic/                # Plastic waste images
â”‚   â””â”€â”€ paper/                  # Paper waste images
â””â”€â”€ test/                       # Test images for evaluation
```

- **README.md**: Instructions for reproducing the training experiments and visualizing model attention via Grad-CAM.
- **garbage-classification.ipynb**: Data preprocessing, augmentation, training with EfficientNetB0, evaluation metrics, and Grad-CAM interpretability.
- **global-classification/**: Contains categorized raw images for training and validation.
- **test/**: Contains holdout images used for final model evaluation.

---

### 2. Robot

Implements the real-world sorting system:
- **README.md**: Prerequisites, network setup (default IP `10.10.10.10`), saving Niryo Studio poses (`watch`, `pick`, `metalbin`, `paperbin`, `plasticbin`), and running scripts.
- **classify_function.py**: Loads the Keras classification model (`best_efficientnetb0_garbage.keras`) to predict waste categories.
- **watchy.py**: Coordinates pose movements, image capture, classification, and bin placement via the Niryo Python API (pyniryo2).
- **captured_image.jpg**: Sample image used for testing classification without hardware.

Model weights are located in `Robot/best_efficientnetb0_garbage.keras/`:
```plaintext
Robot/best_efficientnetb0_garbage.keras/
â”œâ”€â”€ config.json            # Model architecture configuration
â”œâ”€â”€ model.weights.h5       # Trained weights file
â””â”€â”€ metadata.json          # Training metadata and environment details
```

---

### 3. Simulation

Provides a virtual testbed when hardware is unavailable:
- **README.md**: Instructions for running the simulation and visualizing the sorting workflow in a virtual environment.

---

- **Python 3.x**
- **TensorFlow / Keras** (EfficientNetB0)
- **OpenCV**
- **Ultralytics YOLOv8** (for multi-object detection extension)
- **pyniryo2** (Niryo One Python API)
- **Jupyter Notebooks**
- **OS**: Linux (WSL/Ubuntu) or Windows

---

## ðŸš€ Future Enhancements

- Expand classification to additional materials like glass and organic waste.
- Integrate YOLOv8 for simultaneous multi-object detection and sorting.
- Develop a real-time dashboard for monitoring robot performance.
- Port the system to edge devices (e.g., NVIDIA Jetson Nano, Raspberry Pi).

---
