# Robotics Project: Automated Garbage Classification

**Automated Garbage Classification Robot**

This repository implements an end-to-end system for automatically classifying and sorting dry waste using a Niryo One robotic arm, deep learning-based vision models, and both real-world and simulated environments.

---

## Repository Structure

```plaintext
.
â”œâ”€â”€ Model/                                  # Image classification pipeline
â”‚   â”œâ”€â”€ README.md                           # Model training, evaluation, and interpretability
â”‚   â””â”€â”€ garbage-classification.ipynb        # Jupyter notebook with data exploration and training
â”œâ”€â”€ Robot/                                  # Niryo One integration and hardware control
â”‚   â”œâ”€â”€ README.md                           # Setup and usage instructions for physical hardware
â”‚   â”œâ”€â”€ classify_function.py                # Image classification helper using EfficientNetB0
â”‚   â”œâ”€â”€ watchy.py                           # Main sorting workflow controlling the robot
â”‚   â””â”€â”€ captured_image.jpg                  # Example snapshot from the robot camera
â”œâ”€â”€ Simulation/                             # Virtual testing environment in Webots
â”‚   â”œâ”€â”€ worlds/                             # Simulation world definitions
â”‚   â”‚   â”œâ”€â”€ arm_robot.wbt                   # Main world file with UR5e setup and environment
â”‚   â”‚   â””â”€â”€ .arm_robot.wbproj              # Webots project configuration file
â”‚   â””â”€â”€ controllers/                        # Robot control scripts
â”‚       â””â”€â”€ simple_pick_place/              # Pick and place controller
â”‚           â”œâ”€â”€ simple_pick_place.py        # Main robot control logic
â”‚           â””â”€â”€ __init__.py 
â””â”€â”€ README.md                               # Overview of full robotics project (this file)
```

---

## Module Descriptions

### 1. Model

Contains the deep learning pipeline and dataset organization for waste classification:

```plaintext
Model/
â”œâ”€â”€ README.md                   # Detailed instructions for training and evaluation
â”œâ”€â”€ garbage-classification.ipynb# Jupyter notebook with data exploration and model training
â”œâ”€â”€ global-classification/      # Raw image dataset organized by category
â”‚   â”œâ”€â”€ metal/                  # Metal waste images
â”‚   â”œâ”€â”€ plastic/                # Plastic waste images
â”‚   â””â”€â”€ paper/                  # Paper waste images
â””â”€â”€ test/                       # Test images for evaluation
```

- **README.md**: Instructions for reproducing the training experiments and visualizing model attention via Grad-CAM.
- **garbage-classification.ipynb**: Data preprocessing, augmentation, training with EfficientNetB0, evaluation metrics, and Grad-CAM interpretability.
- **global-classification/**: Contains categorized raw images for training and validation.
- **test/**: Contains holdout images used for final model evaluation.

---

### 2. Robot

Implements the real-world sorting system:
- **README.md**: Prerequisites, network setup (default IP `10.10.10.10`), saving Niryo Studio poses (`watch`, `pick`, `metalbin`, `paperbin`, `plasticbin`), and running scripts.
- **classify_function.py**: Loads the Keras classification model (`best_efficientnetb0_garbage.keras`) to predict waste categories.
- **watchy.py**: Coordinates pose movements, image capture, classification, and bin placement via the Niryo Python API (pyniryo2).
- **captured_image.jpg**: Sample image used for testing classification without hardware.

Model weights are located in `Robot/best_efficientnetb0_garbage.keras/`:
```plaintext
Robot/best_efficientnetb0_garbage.keras/
â”œâ”€â”€ config.json            # Model architecture configuration
â”œâ”€â”€ model.weights.h5       # Trained weights file
â””â”€â”€ metadata.json          # Training metadata and environment details
```

---

### 3. Simulation

The simulation implements a robotic waste classification system with the following components:

1. **Robot Setup**:
   - Universal Robots UR5e robotic arm mounted on a fixed base
   - Robotiq 3-finger gripper for object manipulation
   - JetBot Raspberry Pi Camera for object detection and classification

2. **Environment**:
   - Factory-themed background with proper lighting
   - 10x10 meter arena with parquet flooring
   - Three colored boxes representing different types of waste:
     - Red box
     - Green box
     - Blue box
   - Three designated bins for waste sorting

3. **Functionality**:
   - The robot uses computer vision to identify waste objects
   - Pick and place operations are simulated with precise joint control
   - The gripper can perform basic open/close operations
   - Objects are sorted into their respective bins based on classification

The simulation serves as a testbed for developing and validating waste classification algorithms and robot control strategies before deployment on physical hardware.
---

- **Python 3.x**
- **TensorFlow / Keras** (EfficientNetB0)
- **OpenCV**
- **Ultralytics YOLOv8** (for multi-object detection extension)
- **pyniryo2** (Niryo One Python API)
- **Jupyter Notebooks**
- **OS**: Linux (WSL/Ubuntu) or Windows

---

## ðŸš€ Future Enhancements

- Expand classification to additional materials like glass and organic waste.
- Integrate YOLOv8 for simultaneous multi-object detection and sorting.
- Develop a real-time dashboard for monitoring robot performance.
- Port the system to edge devices (e.g., NVIDIA Jetson Nano, Raspberry Pi).

---
